# -*- coding: utf-8 -*-
"""Copy of FINAL_yelp_proj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-xR6H_r26prt0Y9TvU6I42fwMSjFNa9j
"""

import pandas as pd
import pandas as pd
import collections
import scipy.sparse as sp
import matplotlib.pyplot as plt
import itertools
import numpy as np
import operator
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils.np_utils import to_categorical
from sklearn.model_selection import train_test_split

from keras.models import Sequential
from keras.layers import Dense, LSTM, GRU, Flatten, Dropout
from keras.layers.embeddings import Embedding
from keras.preprocessing import sequence

#random number generator 
np.random.seed(0)

MAX_SEQUENCE_LENGTH = 1000
MAX_NUM_WORDS = 20000
VALIDATION_SPLIT = 0.2

df_reviews = pd.read_csv('yelp_academic_dataset_review.csv', nrows=500000)

df_reviews['len'] = df_reviews.text.str.len()
df_reviews = df_reviews[df_reviews['len'].between(10, 4000)]


##creating new dataframes for the individual star ratings 
one_star = df_reviews.loc[df_reviews['stars'] == 1]
two_star = df_reviews.loc[df_reviews['stars'] == 2]
three_star = df_reviews.loc[df_reviews['stars'] == 3]
four_star = df_reviews.loc[df_reviews['stars'] == 4]
five_star = df_reviews.loc[df_reviews['stars'] == 5]

##before balancing, will return number of 1,2,4,5 stars 
print(len(one_star))
print(len(two_star))
print(len(three_star))
print(len(four_star))
print(len(five_star))



##balancing --> concatenated a new dataframe with equivalent number of reviews per star 
#returns 5 diff dataframes 
#taking the top 45,000 rows in each star column 

rows = 45000

one_star_balanced = one_star.head(rows)
two_star_balanced = two_star.head(rows)
three_star_balanced = three_star.head(rows)
four_star_balanced = four_star.head(rows)
five_star_balanced = five_star.head(rows)


frames = [one_star_balanced, two_star_balanced, three_star_balanced, four_star_balanced, five_star_balanced]

df_reviews = pd.concat(frames)

#overwrites the original df_reviews into the concatentaed dataframe 

#all the stars put together, but a fixed amount for each one 

#our stars are all in order, so we need to do a shuffle.  


df_reviews = df_reviews.sample(frac=1)

df_reviews

print(df_reviews.iloc[0])
print(df_reviews.shape)

tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)
tokenizer.fit_on_texts(df_reviews.text.tolist())

WORD_INDEX_SORTED = sorted(tokenizer.word_index.items(), key=operator.itemgetter(1))

seqs = tokenizer.texts_to_sequences(df_reviews.text.values)
X = pad_sequences(seqs, maxlen=MAX_SEQUENCE_LENGTH)
print(X.shape)

Y = df_reviews.stars.values.astype(int)
Y_cat = to_categorical(Y)
print(Y_cat)

assert X.shape[0] == Y.shape[0]  
X_train, X_test, y_train, y_test = train_test_split(X, Y_cat, test_size=0.2, random_state=9)
num_words = min(MAX_NUM_WORDS, len(WORD_INDEX_SORTED)) + 1

print(num_words)
print(WORD_INDEX_SORTED)
print(df_reviews.shape)

model = Sequential()

model.add(Embedding(input_dim=num_words, 
                    output_dim=100, 
                    input_length=MAX_SEQUENCE_LENGTH))

model.add(GRU(100, return_sequences=True)) #100 nodes in each GRU, will drop out 20% of the nodes in the previous layer
#dont wanna be overly dependent on specific nodes so we're preventing model from overfitting


model.add(Dropout(0.2)) #dropout is a way of preventing overfitting 
model.add(GRU(100))
model.add(Dropout(0.2))
model.add(Dense(6, activation='softmax'))

#last layer we have 6 nodes for each category 0,1,2,3,4,5
#want to represent each category as a probablity, essentailly just normalizing all values add up to 1 


model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

print(model.summary())
model.fit(X_train, y_train, 
          epochs=4, 
          batch_size=128, 
          validation_data=(X_test, y_test))

model.save("yelp.model")

##insert any review 

#review = "My recent visit with this location was HORRIBLE....If i could give this Starbucks-10 I WOULD.. I went to order my favorite hibiscus drink and also my husband FREE birthday DRINK...mind you my husband has been a Starbucks member for over 2 years or so...the coupon didn't show up on his app so we tried to show him on his birthday his id that it was actually his birthday the girl simply replied by being snappy"

review = "This starbucks is just okay. I think the location is too small for the volume of people they get. Since its right across from Columbia University, it can get pretty packed sometimes. There is ALWAYS a line during the morning, so I recommend ordering through the app. Even then, the wait can be long. I had to wait about 10 minutes today for a caramel macchiato despite ordering in advance."

seq=tokenizer.texts_to_sequences([review])

seq_pad = pad_sequences(seq,maxlen=1000)

print("number of stars:")
model.predict_classes(seq_pad)[0]